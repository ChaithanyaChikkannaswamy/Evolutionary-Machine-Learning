{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/bank marketing.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import csv \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "from keras.layers import Concatenate, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import h5py\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../input/bank marketing.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'balance',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'day',\n",
       " 'month',\n",
       " 'duration',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'poutcome',\n",
       " 'market?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['job', 'marital','education','contact','month','poutcome'], axis = 1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'default',\n",
       " 'balance',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'day',\n",
       " 'duration',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'market?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values\n",
    "X = data[:,0:10]\n",
    "Y = data[:,10]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 241\n",
      "Trainable params: 241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, activation='sigmoid', input_shape=(10,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3390/3390 [==============================] - 1s 428us/step - loss: 0.3818 - accuracy: 0.8794\n",
      "Epoch 2/10\n",
      "3390/3390 [==============================] - 1s 326us/step - loss: 0.3495 - accuracy: 0.8841\n",
      "Epoch 3/10\n",
      "3390/3390 [==============================] - 1s 328us/step - loss: 0.3362 - accuracy: 0.8841\n",
      "Epoch 4/10\n",
      "3390/3390 [==============================] - 1s 326us/step - loss: 0.3271 - accuracy: 0.8841\n",
      "Epoch 5/10\n",
      "3390/3390 [==============================] - 1s 331us/step - loss: 0.3252 - accuracy: 0.8841\n",
      "Epoch 6/10\n",
      "3390/3390 [==============================] - 1s 326us/step - loss: 0.3263 - accuracy: 0.8841\n",
      "Epoch 7/10\n",
      "3390/3390 [==============================] - 1s 326us/step - loss: 0.3273 - accuracy: 0.8841\n",
      "Epoch 8/10\n",
      "3390/3390 [==============================] - 1s 321us/step - loss: 0.3256 - accuracy: 0.8876\n",
      "Epoch 9/10\n",
      "3390/3390 [==============================] - 1s 327us/step - loss: 0.3224 - accuracy: 0.8861\n",
      "Epoch 10/10\n",
      "3390/3390 [==============================] - 1s 331us/step - loss: 0.3288 - accuracy: 0.8817\n"
     ]
    }
   ],
   "source": [
    "model.compile( optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'] )\n",
    "hist = model.fit(X_train, y_train, batch_size=4, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.889478325843811\n",
      "\n",
      " Test loss:  0.3081013898897972\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "print('\\n Test loss: ', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GA\n",
    "class GeneticNeuralNetwork(Sequential):\n",
    "    # Constructor\n",
    "    def __init__(self, child_weights=None):\n",
    "        # Initialize Sequential Model Super Class\n",
    "        super().__init__()\n",
    "        # If no weights provided randomly generate them\n",
    "        if child_weights is None:\n",
    "            # Layers are created and randomly generated\n",
    "            layer1 = Dense(20, input_shape=(10,), activation='sigmoid')\n",
    "            layer2 = Dense(1, activation='sigmoid')\n",
    "            # Layers are added to the model\n",
    "            self.add(layer1)\n",
    "            self.add(layer2)\n",
    "        # If weights are provided set them within the layers\n",
    "        else:\n",
    "            # Set weights within the layers\n",
    "            self.add(\n",
    "                Dense(\n",
    "                    20,\n",
    "                    input_shape=(10,),\n",
    "                    activation='sigmoid',\n",
    "                    weights=[child_weights[0], np.zeros(20)])\n",
    "                )\n",
    "            self.add(\n",
    "                Dense(\n",
    "                 1,\n",
    "                 activation='sigmoid',\n",
    "                 weights=[child_weights[1], np.zeros(1)])\n",
    "            )\n",
    "\n",
    "    # Function for forward propagating a row vector of a matrix\n",
    "    def forward_propagation(self, X_train, y_train):\n",
    "        # Forward propagation\n",
    "        ########3\n",
    "        y_hat = self.predict(X_train)\n",
    "        # Compute fitness score\n",
    "        self.fitness = accuracy_score(y_train, y_hat.round())\n",
    "\n",
    "    # Standard Backpropagation\n",
    "    def compile_train(self, epochs):\n",
    "        self.compile(\n",
    "                      optimizer='rmsprop',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy']\n",
    "                      )\n",
    "        #############\n",
    "        self.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chance to mutate weights\n",
    "def mutation(child_weights):\n",
    "    # Add a chance for random mutation\n",
    "    selection = random.randint(0, len(child_weights)-1)\n",
    "    mut = random.uniform(0, 1)\n",
    "    if mut >= .7:\n",
    "        child_weights[selection] *= random.randint(2, 5)\n",
    "    else:\n",
    "        # No mutation\n",
    "        pass\n",
    "\n",
    "\n",
    "# Crossover traits between two Genetic Neural Networks\n",
    "def dynamic_crossover(nn1, nn2):\n",
    "    # Lists for respective weights\n",
    "    nn1_weights = []\n",
    "    nn2_weights = []\n",
    "    child_weights = []\n",
    "    # Get all weights from all layers in the first network\n",
    "    for layer in nn1.layers:\n",
    "        nn1_weights.append(layer.get_weights()[0])\n",
    "\n",
    "    # Get all weights from all layers in the second network\n",
    "    for layer in nn2.layers:\n",
    "        nn2_weights.append(layer.get_weights()[0])\n",
    "\n",
    "    # Iterate through all weights from all layers for crossover\n",
    "    for i in range(0, len(nn1_weights)):\n",
    "        # Get single point to split the matrix in parents based on # of cols\n",
    "        split = random.randint(0, np.shape(nn1_weights[i])[1]-1)\n",
    "        # Iterate through after a single point and set the remaing cols to nn_2\n",
    "        for j in range(split, np.shape(nn1_weights[i])[1]-1):\n",
    "            nn1_weights[i][:, j] = nn2_weights[i][:, j]\n",
    "\n",
    "        # After crossover add weights to child\n",
    "        child_weights.append(nn1_weights[i])\n",
    "\n",
    "    # Add a chance for mutation\n",
    "    mutation(child_weights)\n",
    "\n",
    "    # Create and return child object\n",
    "    child = GeneticNeuralNetwork(child_weights)\n",
    "    return child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation:  1\n",
      "Max Fitness:  0.8840707964601769\n",
      "[array([[ 0.13318026,  0.1603396 ,  0.02078304, -0.30280423, -0.35221553,\n",
      "         0.03362378,  0.13438094,  0.34500313, -0.25380635, -0.2603329 ,\n",
      "         0.37509078, -0.1704962 ,  0.3816538 ,  0.22451192,  0.42015797,\n",
      "        -0.09756175,  0.23120302, -0.19912656,  0.02710906,  0.14633828],\n",
      "       [ 0.02724329,  0.11032677,  0.00284281,  0.10588813, -0.35592902,\n",
      "        -0.2865877 ,  0.07846856,  0.28864145,  0.15698832,  0.3745911 ,\n",
      "        -0.23784664, -0.10857034, -0.29291007, -0.38541567,  0.09456825,\n",
      "         0.12792718, -0.27768874,  0.29161257,  0.00475767,  0.4460271 ],\n",
      "       [ 0.21324432,  0.00135499,  0.37498635, -0.04907617, -0.19480306,\n",
      "         0.24257147,  0.3180967 , -0.20143987,  0.07098109, -0.35472512,\n",
      "         0.22094482, -0.04530048,  0.18020356,  0.25437486, -0.08060318,\n",
      "        -0.308841  , -0.31239676,  0.37906933, -0.05382189, -0.22148477],\n",
      "       [ 0.23079753,  0.12943274, -0.06678364, -0.29206774,  0.38609564,\n",
      "         0.3652935 , -0.34149736, -0.28231505,  0.42921853,  0.3961779 ,\n",
      "        -0.3380214 , -0.24298134,  0.2993123 , -0.41771337,  0.08385265,\n",
      "        -0.38627946,  0.2432642 , -0.08515623, -0.38763356,  0.17344594],\n",
      "       [-0.00534922, -0.1216656 ,  0.43156767, -0.33802813,  0.17426836,\n",
      "         0.41757125,  0.17141175, -0.3010569 , -0.13802415, -0.42393565,\n",
      "         0.360592  , -0.199916  ,  0.23454738,  0.2488336 ,  0.13543642,\n",
      "         0.40955633, -0.34663963, -0.08801344,  0.01969719,  0.36727864],\n",
      "       [-0.06975579,  0.00319424,  0.01488972,  0.3666649 ,  0.1701442 ,\n",
      "         0.32214284, -0.22007178, -0.35774153, -0.1990371 ,  0.257662  ,\n",
      "        -0.21983156, -0.308323  , -0.39629006, -0.20687471, -0.38992962,\n",
      "         0.04507691,  0.28510714, -0.04280442, -0.38120884,  0.05613607],\n",
      "       [ 0.09146559,  0.44026768,  0.24020582,  0.01023057, -0.02883029,\n",
      "         0.12656754,  0.32268578, -0.22591788,  0.13214886,  0.10194951,\n",
      "        -0.2615527 ,  0.31679618, -0.3885628 ,  0.2314009 , -0.3057828 ,\n",
      "         0.10826969,  0.21004516,  0.33615845,  0.1770795 , -0.33256355],\n",
      "       [ 0.04764155, -0.32261658, -0.16618153, -0.4084452 , -0.07166213,\n",
      "        -0.1205647 ,  0.37140453, -0.02148473, -0.26706046, -0.37113756,\n",
      "         0.3904544 ,  0.27409518, -0.25455293,  0.0956912 , -0.26675743,\n",
      "        -0.26856387,  0.15079921,  0.2581371 , -0.08191326,  0.30280447],\n",
      "       [-0.31718835,  0.24133605, -0.11491895,  0.41953897,  0.31178582,\n",
      "        -0.02166814, -0.3579294 , -0.36853412, -0.01306826,  0.16239244,\n",
      "        -0.14630127, -0.10975185, -0.32083052, -0.01831406, -0.14970759,\n",
      "         0.32066762,  0.07789707, -0.20699424, -0.43663585,  0.24927396],\n",
      "       [ 0.06272501,  0.21872371,  0.03243279,  0.0551421 ,  0.3349226 ,\n",
      "        -0.25147033, -0.11363861, -0.31565118,  0.10556698,  0.233365  ,\n",
      "         0.03718662, -0.10062194,  0.23602337, -0.17068705, -0.21265362,\n",
      "         0.1642031 ,  0.35746568,  0.20573545, -0.4070896 ,  0.14431256]],\n",
      "      dtype=float32), array([[ 0.3461303 ],\n",
      "       [-0.43024272],\n",
      "       [ 0.43639946],\n",
      "       [-0.01676691],\n",
      "       [-0.47033256],\n",
      "       [-0.12388566],\n",
      "       [-0.45548195],\n",
      "       [-0.46061805],\n",
      "       [-0.21232602],\n",
      "       [-0.46825427],\n",
      "       [-0.4877108 ],\n",
      "       [ 0.3797558 ],\n",
      "       [ 0.38047534],\n",
      "       [-0.5028035 ],\n",
      "       [ 0.44789356],\n",
      "       [-0.12888846],\n",
      "       [-0.14365008],\n",
      "       [-0.46645927],\n",
      "       [-0.34507132],\n",
      "       [-0.4238767 ]], dtype=float32)]\n",
      "Generation:  2\n",
      "Generation:  3\n",
      "Generation:  4\n",
      "Generation:  5\n",
      "Generation:  6\n",
      "Generation:  7\n",
      "Generation:  8\n",
      "Generation:  9\n",
      "Generation:  10\n",
      "Generation:  11\n",
      "Generation:  12\n",
      "Generation:  13\n",
      "Generation:  14\n",
      "Generation:  15\n",
      "Generation:  16\n",
      "Generation:  17\n",
      "Generation:  18\n",
      "Generation:  19\n",
      "Generation:  20\n",
      "Generation:  21\n",
      "Generation:  22\n",
      "Generation:  23\n",
      "Generation:  24\n",
      "Generation:  25\n",
      "Generation:  26\n",
      "Generation:  27\n",
      "Generation:  28\n",
      "Generation:  29\n",
      "Generation:  30\n",
      "Generation:  31\n",
      "Generation:  32\n",
      "Generation:  33\n",
      "Generation:  34\n",
      "Generation:  35\n",
      "Generation:  36\n",
      "Generation:  37\n",
      "Generation:  38\n",
      "Generation:  39\n",
      "Generation:  40\n",
      "Generation:  41\n",
      "Generation:  42\n",
      "Generation:  43\n",
      "Generation:  44\n",
      "Generation:  45\n",
      "Generation:  46\n",
      "Generation:  47\n",
      "Generation:  48\n",
      "Generation:  49\n",
      "Generation:  50\n",
      "Generation:  51\n",
      "Generation:  52\n",
      "Generation:  53\n",
      "Generation:  54\n",
      "Generation:  55\n",
      "Generation:  56\n",
      "Generation:  57\n",
      "Generation:  58\n",
      "Generation:  59\n",
      "Generation:  60\n",
      "Generation:  61\n",
      "Generation:  62\n",
      "Generation:  63\n",
      "Generation:  64\n",
      "Generation:  65\n",
      "Generation:  66\n",
      "Generation:  67\n",
      "Generation:  68\n",
      "Generation:  69\n",
      "Generation:  70\n",
      "Generation:  71\n",
      "Generation:  72\n",
      "Generation:  73\n",
      "Generation:  74\n",
      "Generation:  75\n",
      "Generation:  76\n",
      "Generation:  77\n",
      "Generation:  78\n",
      "Generation:  79\n",
      "Generation:  80\n",
      "Generation:  81\n",
      "Generation:  82\n",
      "Generation:  83\n",
      "Generation:  84\n",
      "Generation:  85\n",
      "Generation:  86\n",
      "Generation:  87\n",
      "Generation:  88\n",
      "Generation:  89\n",
      "Generation:  90\n",
      "Generation:  91\n",
      "Generation:  92\n",
      "Generation:  93\n",
      "Generation:  94\n",
      "Generation:  95\n",
      "Generation:  96\n",
      "Generation:  97\n",
      "Generation:  98\n",
      "Generation:  99\n",
      "Generation:  100\n",
      "Generation:  101\n",
      "Generation:  102\n",
      "Generation:  103\n",
      "Generation:  104\n",
      "Generation:  105\n",
      "Generation:  106\n",
      "Generation:  107\n",
      "Generation:  108\n",
      "Generation:  109\n",
      "Generation:  110\n",
      "Generation:  111\n",
      "Generation:  112\n",
      "Generation:  113\n",
      "Generation:  114\n",
      "Generation:  115\n",
      "Generation:  116\n",
      "Generation:  117\n",
      "Generation:  118\n",
      "Generation:  119\n",
      "Generation:  120\n",
      "Generation:  121\n",
      "Generation:  122\n",
      "Generation:  123\n",
      "Generation:  124\n",
      "Generation:  125\n",
      "Generation:  126\n",
      "Generation:  127\n",
      "Generation:  128\n",
      "Generation:  129\n",
      "Generation:  130\n",
      "Generation:  131\n",
      "Generation:  132\n",
      "Generation:  133\n",
      "Generation:  134\n",
      "Generation:  135\n",
      "Generation:  136\n",
      "Generation:  137\n",
      "Generation:  138\n",
      "Generation:  139\n",
      "Generation:  140\n",
      "Generation:  141\n",
      "Generation:  142\n",
      "Generation:  143\n",
      "Generation:  144\n",
      "Generation:  145\n",
      "Generation:  146\n",
      "Generation:  147\n",
      "Generation:  148\n",
      "Generation:  149\n",
      "Generation:  150\n",
      "Generation:  151\n",
      "Generation:  152\n",
      "Generation:  153\n",
      "Generation:  154\n",
      "Generation:  155\n",
      "Generation:  156\n",
      "Generation:  157\n",
      "Generation:  158\n",
      "Generation:  159\n",
      "Generation:  160\n",
      "Generation:  161\n",
      "Generation:  162\n",
      "Generation:  163\n",
      "Generation:  164\n",
      "Generation:  165\n",
      "Generation:  166\n",
      "Generation:  167\n",
      "Generation:  168\n",
      "Generation:  169\n",
      "Generation:  170\n",
      "Generation:  171\n",
      "Generation:  172\n",
      "Generation:  173\n",
      "Generation:  174\n",
      "Generation:  175\n",
      "Generation:  176\n",
      "Generation:  177\n",
      "Generation:  178\n",
      "Generation:  179\n",
      "Generation:  180\n",
      "Generation:  181\n",
      "Generation:  182\n",
      "Generation:  183\n",
      "Generation:  184\n",
      "Generation:  185\n",
      "Generation:  186\n",
      "Generation:  187\n",
      "Generation:  188\n",
      "Generation:  189\n",
      "Generation:  190\n",
      "Generation:  191\n",
      "Generation:  192\n",
      "Generation:  193\n",
      "Generation:  194\n",
      "Generation:  195\n",
      "Generation:  196\n",
      "Generation:  197\n",
      "Generation:  198\n",
      "Generation:  199\n",
      "Generation:  200\n",
      "Generation:  201\n",
      "Generation:  202\n",
      "Generation:  203\n",
      "Generation:  204\n",
      "Generation:  205\n",
      "Generation:  206\n",
      "Generation:  207\n",
      "Generation:  208\n",
      "Generation:  209\n",
      "Generation:  210\n",
      "Generation:  211\n",
      "Generation:  212\n",
      "Generation:  213\n",
      "Generation:  214\n",
      "Generation:  215\n",
      "Generation:  216\n",
      "Generation:  217\n",
      "Generation:  218\n",
      "Generation:  219\n",
      "Generation:  220\n",
      "Generation:  221\n",
      "Generation:  222\n",
      "Generation:  223\n",
      "Generation:  224\n",
      "Generation:  225\n",
      "Generation:  226\n",
      "Generation:  227\n",
      "Generation:  228\n",
      "Generation:  229\n",
      "Generation:  230\n",
      "Generation:  231\n",
      "Generation:  232\n",
      "Generation:  233\n",
      "Generation:  234\n",
      "Generation:  235\n",
      "Generation:  236\n",
      "Generation:  237\n",
      "Generation:  238\n",
      "Generation:  239\n",
      "Generation:  240\n",
      "Generation:  241\n",
      "Generation:  242\n",
      "Generation:  243\n",
      "Generation:  244\n",
      "Generation:  245\n",
      "Generation:  246\n",
      "Generation:  247\n",
      "Generation:  248\n",
      "Generation:  249\n",
      "Generation:  250\n",
      "Epoch 1/10\n",
      "3390/3390 [==============================] - 0s 74us/step - loss: 0.3628 - accuracy: 0.8841\n",
      "Epoch 2/10\n",
      "3390/3390 [==============================] - 0s 42us/step - loss: 0.3534 - accuracy: 0.8841\n",
      "Epoch 3/10\n",
      "3390/3390 [==============================] - 0s 44us/step - loss: 0.3485 - accuracy: 0.8841\n",
      "Epoch 4/10\n",
      "3390/3390 [==============================] - 0s 43us/step - loss: 0.3437 - accuracy: 0.8841\n",
      "Epoch 5/10\n",
      "3390/3390 [==============================] - 0s 43us/step - loss: 0.3374 - accuracy: 0.8841\n",
      "Epoch 6/10\n",
      "3390/3390 [==============================] - 0s 43us/step - loss: 0.3318 - accuracy: 0.8841\n",
      "Epoch 7/10\n",
      "3390/3390 [==============================] - 0s 42us/step - loss: 0.3257 - accuracy: 0.8841\n",
      "Epoch 8/10\n",
      "3390/3390 [==============================] - 0s 51us/step - loss: 0.3207 - accuracy: 0.8841\n",
      "Epoch 9/10\n",
      "3390/3390 [==============================] - 0s 42us/step - loss: 0.3138 - accuracy: 0.8841\n",
      "Epoch 10/10\n",
      "3390/3390 [==============================] - 0s 42us/step - loss: 0.3083 - accuracy: 0.8841\n",
      "Test Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "networks = []\n",
    "pool = []\n",
    "# Track Generations\n",
    "generation = 0\n",
    "# Initial Population\n",
    "n = 25\n",
    "\n",
    "# Generate n randomly weighted neural networks\n",
    "for i in range(0, n):\n",
    "    networks.append(GeneticNeuralNetwork())\n",
    "\n",
    "# Cache Max Fitness\n",
    "max_fitness = 0\n",
    "\n",
    "# Max Fitness Weights\n",
    "optimal_weights = []\n",
    "\n",
    "# Evolution Loop\n",
    "while (max_fitness < .90 and generation < 250):\n",
    "    # Log the current generation\n",
    "    generation += 1\n",
    "    print('Generation: ', generation)\n",
    "\n",
    "    # Forward propagate the neural networks to compute a fitness score\n",
    "    for nn in networks:\n",
    "        # Propagate to calculate fitness score\n",
    "        nn.forward_propagation(X_train, y_train)\n",
    "        # Add to pool after calculating fitness\n",
    "        pool.append(nn)\n",
    "\n",
    "    # Clear for propagation of next children\n",
    "    networks.clear()\n",
    "\n",
    "    # Sort based on fitness\n",
    "    pool = sorted(pool, key=lambda x: x.fitness)\n",
    "    pool.reverse()\n",
    "\n",
    "    # Find Max Fitness and Log Associated Weights\n",
    "    for i in range(0, len(pool)):\n",
    "        # If there is a new max fitness among the population\n",
    "        if pool[i].fitness > max_fitness:\n",
    "            max_fitness = pool[i].fitness\n",
    "            print('Max Fitness: ', max_fitness)\n",
    "            # Reset optimal_weights\n",
    "            optimal_weights = []\n",
    "            # Iterate through layers, get weights, and append to optimal\n",
    "            for layer in pool[i].layers:\n",
    "                optimal_weights.append(layer.get_weights()[0])\n",
    "            print(optimal_weights)\n",
    "\n",
    "    # Crossover, top 5 randomly select 2 partners for child\n",
    "    for i in range(0, 5):\n",
    "        for j in range(0, 2):\n",
    "            # Create a child and add to networks\n",
    "            temp = dynamic_crossover(pool[i], random.choice(pool))\n",
    "            # Add to networks to calculate fitness score next iteration\n",
    "            networks.append(temp)\n",
    "\n",
    "# Create a Genetic Neural Network with optimal initial weights\n",
    "gnn = GeneticNeuralNetwork(optimal_weights)\n",
    "gnn.compile_train(10)\n",
    "\n",
    "# Test the Genetic Neural Network Out of Sample\n",
    "##############3\n",
    "y_hat = gnn.predict(X_test)\n",
    "print('Test Accuracy: %.2f' % accuracy_score(y_test, y_hat.round()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
